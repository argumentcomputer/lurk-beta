# Run final tests only when attempting to merge, shown as skipped status checks beforehand
name: Merge group tests

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
    branches: [master]
  merge_group:
  # Manual trigger for early signal on local branches
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  linux-ignored:
    if: github.event_name != 'pull_request' || github.event.action == 'enqueued'
    runs-on: buildjet-16vcpu-ubuntu-2204
    env:
      RUSTFLAGS: -D warnings
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: actions-rs/toolchain@v1
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: Linux Tests
        run: |
          cargo nextest run --profile ci --workspace --cargo-profile dev-ci --run-ignored ignored-only -E 'all() - test(groth16::tests::outer_prove_recursion) - test(test_make_fcomm_examples) - test(test_functional_commitments_demo) - test(test_chained_functional_commitments_demo)'

  linux-arm:
    if: github.event_name != 'pull_request' || github.event.action == 'enqueued'
    runs-on: buildjet-16vcpu-ubuntu-2204-arm
    env:
      RUSTFLAGS: -D warnings
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: actions-rs/toolchain@v1
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: Linux Tests
        run: |
          cargo nextest run --profile ci --workspace --cargo-profile dev-ci
      - name: Linux Gadget Tests w/o debug assertions
        run: |
          cargo nextest run --profile ci --workspace --cargo-profile dev-no-assertions -E 'test(circuit::gadgets)'

  mac-m1:
    if: github.event_name != 'pull_request' || github.event.action == 'enqueued'
    runs-on: macos-latest-xlarge
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
      - uses: actions-rs/toolchain@v1
      - uses: taiki-e/install-action@nextest
      - uses: Swatinem/rust-cache@v2
      - name: Linux Tests
        run: |
          cargo nextest run --profile ci --workspace --cargo-profile dev-ci
      - name: Linux Gadget Tests w/o debug assertions
        run: |
          cargo nextest run --profile ci --workspace --cargo-profile dev-no-assertions -E 'test(circuit::gadgets)'

  # TODO: Make this a required status check
  gpu-benchmark:
    name: Run fibonacci bench on GPU
    runs-on: gpu-bench-a6000
    env:
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITITES: compute,utility
      EC_GPU_FRAMEWORK: cuda
    steps:
      # Checkout and install deps
      - uses: actions/checkout@v4
      - uses: actions-rs/toolchain@v1
      - uses: Swatinem/rust-cache@v2
      - uses: taiki-e/install-action@just

      # Set up GPU
      # Check we have access to the machine's Nvidia drivers
      - run: nvidia-smi
      # The `compute`/`sm` number corresponds to the Nvidia GPU architecture
      # In this case, the self-hosted machine uses the Ampere architecture, but we want this to be configurable
      # See https://arnon.dk/matching-sm-architectures-arch-and-gencode-for-various-nvidia-cards/
      - name: Set env for CUDA compute
        run: echo "CUDA_ARCH=$(nvidia-smi --query-gpu=compute_cap --format=csv,noheader | sed 's/\.//g')" >> $GITHUB_ENV
      - name: set env for EC_GPU
        run: echo 'EC_GPU_CUDA_NVCC_ARGS=--fatbin --gpu-architecture=sm_${{ env.CUDA_ARCH }} --generate-code=arch=compute_${{ env.CUDA_ARCH }},code=sm_${{ env.CUDA_ARCH }}' >> $GITHUB_ENV
      - run: echo "${{ env.EC_GPU_CUDA_NVCC_ARGS}}"
      # Check that CUDA is installed with a driver-compatible version
      # This must also be compatible with the GPU architecture, see above link
      - run: nvcc --version

      # Run benchmark
      - name: Install criterion
        run: cargo install cargo-criterion
      # TODO: Write this in a commit comment, reject if there's a regression
      - name: Run benchmarks
        run: just --dotenv-filename bench.env gpu-bench
